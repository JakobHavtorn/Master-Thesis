%!TEX root = ../Thesis.tex

\section{Scope and delimitations}
This thesis seeks to unify previous work done within black-box and non-differentiable optimization with recent advances within deep learning. It seeks to find a broader mathematical framework for describing \gls{ES} as Monte Carlo based stochastic gradient estimator and to further analyze the properties of the estimator. Effort is put towards reducing the variance of the estimator, reducing the amount of required computation and generally improving its performance. Experiments are done to validate the theoretical results of the thesis.

The investigative nature of the work of this thesis has lead to consideration of a very broad range of literature. Consequently, the associated set of related material is immense and as such, many related methods may have been only superficially noted or even overlooked. 

% % \todo[inline]{Finish writing the scope and delimitations}

% variations of the algorithm

% performance and robustness

% variance reduction

% exploit special structure of neural networks

% \todo[inline]{Scope and delimitations - read in context of previous and following sections - need it?}
